{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR operation by Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.709144 [[-0.65679926 -0.18958679]\n",
      " [ 0.12794963  0.81384182]] [[ 0.61581868]\n",
      " [ 0.16675976]]\n",
      "1000 0.692954 [[-0.68498749 -0.1935062 ]\n",
      " [ 0.21847157  0.81189352]] [[ 0.50370032]\n",
      " [-0.04746513]]\n",
      "2000 0.69239 [[-0.76409727 -0.22777221]\n",
      " [ 0.34441516  0.83107841]] [[ 0.54096526]\n",
      " [-0.13836476]]\n",
      "3000 0.689815 [[-0.98998111 -0.31162232]\n",
      " [ 0.5799312   0.88689882]] [[ 0.71053863]\n",
      " [-0.27915817]]\n",
      "4000 0.65986 [[-1.78624308 -0.58519751]\n",
      " [ 1.36011374  1.1108408 ]] [[ 1.48578203]\n",
      " [-0.67106932]]\n",
      "5000 0.377295 [[-3.68406963 -2.24369097]\n",
      " [ 3.40342522  2.6310904 ]] [[ 3.9781363 ]\n",
      " [-2.76237702]]\n",
      "6000 0.117037 [[-4.84093666 -4.04099655]\n",
      " [ 4.65694475  4.34624577]] [[ 6.25426626]\n",
      " [-5.48781013]]\n",
      "7000 0.0585975 [[-5.34939718 -4.76098967]\n",
      " [ 5.17598963  5.04990721]] [[ 7.4919095 ]\n",
      " [-6.86068201]]\n",
      "8000 0.0378506 [[-5.64535856 -5.15269041]\n",
      " [ 5.4703517   5.43505526]] [[ 8.28090858]\n",
      " [-7.69874763]]\n",
      "[array([[ 0.03660639],\n",
      "       [ 0.96825677],\n",
      "       [ 0.95039552],\n",
      "       [ 0.03049923]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Implement code for Sung Kim's TF lecture. See https://www.youtube.com/watch?v=9i7FBbcZPMA&feature=youtu.be\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('xor_dataset.txt', unpack=True)\n",
    "\n",
    "# Need to change data structure. THESE LINES ARE DIFFERNT FROM Video BUT IT MAKES THIS CODE WORKS!\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform( [2,2], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [2,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(8001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 'wide' neural network to solve XOR problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.810507 [[ 0.03593338  0.4675028  -0.42452276 -0.30866268 -0.41931269 -0.19097252\n",
      "   0.55209386 -0.20426369  0.60859221  0.18376905]\n",
      " [-0.38751897  0.5298183   0.65148044  0.4019376  -0.98497581 -0.66995054\n",
      "   0.6445483   0.09752972 -0.11443435  0.05719196]] [[-0.22138293]\n",
      " [ 0.93023342]\n",
      " [ 0.67608792]\n",
      " [-0.97943372]\n",
      " [ 0.7728014 ]\n",
      " [ 0.86023867]\n",
      " [ 0.82027453]\n",
      " [ 0.98739898]\n",
      " [-0.73849207]\n",
      " [-0.95119607]]\n",
      "1000 0.641755 [[ 0.05025027  1.21516097 -0.62710214 -0.41050568 -0.0467158   0.02585443\n",
      "   1.4461323  -0.31560913  0.87403572  0.26281512]\n",
      " [-0.33627656  1.23621917  0.5247643   0.88591051 -0.91700304 -0.71362042\n",
      "   1.4789753   0.03446257 -0.28335595  0.11519052]] [[-0.41277894]\n",
      " [ 1.16270149]\n",
      " [ 0.49080515]\n",
      " [-1.38072681]\n",
      " [ 0.52689135]\n",
      " [ 0.69237918]\n",
      " [ 1.33279753]\n",
      " [ 0.78498822]\n",
      " [-1.11178041]\n",
      " [-1.22122526]]\n",
      "2000 0.348656 [[ 0.35511255  2.50769186 -1.19076037 -1.56640136 -0.03631353 -0.02362451\n",
      "   3.03516722 -0.71926391  2.27211785  0.79789889]\n",
      " [-0.09907293  2.56422043  0.48944387  2.65493393 -1.14303195 -1.02171671\n",
      "   3.09633827 -0.10652524 -1.10263336  0.28333515]] [[-0.57838207]\n",
      " [ 2.43979669]\n",
      " [ 0.88546085]\n",
      " [-2.85983729]\n",
      " [ 0.82513964]\n",
      " [ 0.92989391]\n",
      " [ 3.21828794]\n",
      " [ 0.94652307]\n",
      " [-2.38837051]\n",
      " [-1.71733487]]\n",
      "3000 0.105561 [[ 0.63286209  3.22663021 -1.81153905 -2.82104969 -0.07138336 -0.05829586\n",
      "   3.90227938 -1.06911898  3.7866559   1.2588793 ]\n",
      " [ 0.08539344  3.28331017  0.67275703  4.25047255 -1.43181336 -1.33702052\n",
      "   3.96013737 -0.16880023 -2.22299123  0.38950706]] [[-0.72720677]\n",
      " [ 3.45162034]\n",
      " [ 1.58825707]\n",
      " [-4.81257248]\n",
      " [ 1.38108599]\n",
      " [ 1.43648565]\n",
      " [ 4.56965828]\n",
      " [ 1.41604078]\n",
      " [-4.08309793]\n",
      " [-2.17383361]]\n",
      "4000 0.0487494 [[ 0.73717391  3.53071523 -2.16517806 -3.36199594 -0.07105049 -0.04916281\n",
      "   4.24667692 -1.22931254  4.42101908  1.43853509]\n",
      " [ 0.15406668  3.57238555  0.83926314  4.89140129 -1.60843086 -1.52276564\n",
      "   4.28765535 -0.19831227 -2.75042701  0.5198496 ]] [[-0.80130064]\n",
      " [ 3.94505048]\n",
      " [ 1.98987556]\n",
      " [-5.86394262]\n",
      " [ 1.7029134 ]\n",
      " [ 1.73734343]\n",
      " [ 5.18860245]\n",
      " [ 1.68148088]\n",
      " [-4.9872098 ]\n",
      " [-2.42957044]]\n",
      "5000 0.0295963 [[ 0.79141313  3.70103455 -2.39057517 -3.65688157 -0.07083516 -0.04187956\n",
      "   4.43334961 -1.32175684  4.75364876  1.53020728]\n",
      " [ 0.18881519  3.73329329  0.96141773  5.22474289 -1.72250915 -1.64255917\n",
      "   4.46428823 -0.22018115 -3.04738855  0.63210106]] [[-0.84788853]\n",
      " [ 4.23585749]\n",
      " [ 2.24593711]\n",
      " [-6.49078608]\n",
      " [ 1.9005748 ]\n",
      " [ 1.92391276]\n",
      " [ 5.54486895]\n",
      " [ 1.84361875]\n",
      " [-5.5299201 ]\n",
      " [-2.60140538]]\n",
      "6000 0.0206391 [[ 0.82628709  3.81499696 -2.55210257 -3.8501904  -0.07196675 -0.03734427\n",
      "   4.55582047 -1.38443017  4.96602201  1.58875692]\n",
      " [ 0.21033493  3.84124732  1.05622256  5.43638134 -1.80381799 -1.72821438\n",
      "   4.58051872 -0.23797205 -3.24548745  0.72573262]] [[-0.88156253]\n",
      " [ 4.43627405]\n",
      " [ 2.43130279]\n",
      " [-6.92122793]\n",
      " [ 2.03797936]\n",
      " [ 2.05427074]\n",
      " [ 5.78721714]\n",
      " [ 1.95688534]\n",
      " [-5.90623665]\n",
      " [-2.73132563]]\n",
      "7000 0.0155984 [[ 0.85139674  3.89917707 -2.67648721 -3.99076152 -0.07379732 -0.03443925\n",
      "   4.64506674 -1.43091857  5.11752844  1.63148236]\n",
      " [ 0.22526304  3.92130876  1.13338172  5.58669376 -1.86581481 -1.79378927\n",
      "   4.66556215 -0.25313541 -3.39115906  0.80506271]] [[-0.90777326]\n",
      " [ 4.58742571]\n",
      " [ 2.57591772]\n",
      " [-7.24352694]\n",
      " [ 2.14140701]\n",
      " [ 2.15271139]\n",
      " [ 5.96839046]\n",
      " [ 2.04278517]\n",
      " [-6.19049072]\n",
      " [-2.83615971]]\n",
      "8000 0.0124171 [[ 0.87074941  3.96527791 -2.77687359 -4.09976673 -0.07593183 -0.03248227\n",
      "   4.71443462 -1.46738458  5.23328686  1.66532731]\n",
      " [ 0.23638281  3.98441625  1.19833004  5.70111752 -1.91532564 -1.8463757\n",
      "   4.73191786 -0.2664513  -3.50499773  0.87352681]] [[-0.92913306]\n",
      " [ 4.70803356]\n",
      " [ 2.69420671]\n",
      " [-7.49865818]\n",
      " [ 2.22344995]\n",
      " [ 2.23097324]\n",
      " [ 6.11200809]\n",
      " [ 2.11146045]\n",
      " [-6.4171648 ]\n",
      " [-2.9242363 ]]\n",
      "[array([[ 0.00644314],\n",
      "       [ 0.98760694],\n",
      "       [ 0.98728371],\n",
      "       [ 0.01777619]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Use 'wide' neural network (10 neurals) to solve XOR problem. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('xor_dataset.txt', unpack=True)\n",
    "\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Wide network: Use more neurons in each layer. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [10,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(8001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 'Deep' neural network to solve XOR problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.696978 [[ 0.24734968  0.60207188 -0.77929091  0.45870537  0.18110394]\n",
      " [-0.52320302 -0.00692286  0.70473975 -0.8925215   0.49226522]] [[ 0.48073024  0.69555891  0.29164037 -0.12338613]\n",
      " [-0.65053785 -0.58052325 -0.70374703 -0.1465831 ]\n",
      " [-0.04056193 -0.64179486 -0.55849057 -0.47276947]\n",
      " [-0.74256682 -0.08953542  0.54299819  0.2098498 ]\n",
      " [ 0.11086085 -0.83629286 -0.56223291  0.31209701]]\n",
      "1000 0.693104 [[ 0.22065221  0.62755555 -0.78546333  0.45835552  0.2464716 ]\n",
      " [-0.51060456  0.00190646  0.68009019 -0.88174552  0.50345755]] [[ 0.48043922  0.67925894  0.28510249 -0.12252576]\n",
      " [-0.65171254 -0.60347241 -0.71186894 -0.14643791]\n",
      " [-0.03730871 -0.62244809 -0.55152881 -0.4728106 ]\n",
      " [-0.74094552 -0.12258816  0.52983594  0.21229534]\n",
      " [ 0.11235784 -0.84888464 -0.56649983  0.31246713]]\n",
      "2000 0.69298 [[ 0.19560717  0.65167588 -0.79525042  0.46016544  0.31483936]\n",
      " [-0.500799    0.01445571  0.66353071 -0.8742981   0.52380908]] [[ 0.47899938  0.67058802  0.28181773 -0.12198969]\n",
      " [-0.65402889 -0.62143397 -0.71698338 -0.1466758 ]\n",
      " [-0.03403596 -0.60552305 -0.54585212 -0.47232398]\n",
      " [-0.74100435 -0.14703993  0.52099842  0.21447434]\n",
      " [ 0.11310891 -0.86204219 -0.56980449  0.31294248]]\n",
      "3000 0.692819 [[ 0.16919649  0.67775899 -0.80759597  0.46305567  0.39423558]\n",
      " [-0.4939664   0.03301034  0.65379161 -0.86889195  0.55772448]] [[ 0.47765064  0.66468251  0.27904823 -0.12145507]\n",
      " [-0.65606236 -0.64133322 -0.722377   -0.14688753]\n",
      " [-0.02980816 -0.59373397 -0.54213965 -0.4709346 ]\n",
      " [-0.74132335 -0.1687272   0.51295382  0.21668123]\n",
      " [ 0.11474765 -0.88365483 -0.57518423  0.31416202]]\n",
      "4000 0.692542 [[ 0.13897681  0.70897841 -0.82301027  0.46684462  0.49445489]\n",
      " [-0.49037564  0.06068004  0.65077937 -0.86424309  0.61265439]] [[ 0.47638717  0.66248697  0.27644473 -0.12086721]\n",
      " [-0.6578663  -0.66475087 -0.72894782 -0.14703301]\n",
      " [-0.02458661 -0.58596659 -0.53975916 -0.46847445]\n",
      " [-0.74177039 -0.18772668  0.50455469  0.21902382]\n",
      " [ 0.11773989 -0.91872263 -0.58431578  0.31667879]]\n",
      "5000 0.691956 [[ 0.10112311  0.75075161 -0.84250385  0.47165829  0.63282251]\n",
      " [-0.49130458  0.1037578   0.65628713 -0.85896206  0.7041446 ]] [[ 0.4752287   0.667247    0.2738674  -0.12011424]\n",
      " [-0.65941221 -0.69394922 -0.73828369 -0.14702408]\n",
      " [-0.01796947 -0.5809617  -0.53864115 -0.46444979]\n",
      " [-0.74223673 -0.20224281  0.49457148  0.22172065]\n",
      " [ 0.12333065 -0.978037   -0.60178536  0.32192054]]\n",
      "6000 0.690412 [[ 0.04805597  0.81434703 -0.86771232  0.47788236  0.84348851]\n",
      " [-0.49998206  0.17576611  0.67480254 -0.8510108   0.86506528]] [[ 0.4743138   0.68888092  0.27187318 -0.11889496]\n",
      " [-0.66047382 -0.73206151 -0.75370365 -0.1465988 ]\n",
      " [-0.00893236 -0.57505763 -0.53915149 -0.45749366]\n",
      " [-0.74253339 -0.20543456  0.48152891  0.22526087]\n",
      " [ 0.13492866 -1.08614051 -0.64052272  0.33422726]]\n",
      "7000 0.685123 [[-0.03918773  0.92738479 -0.90188414  0.48577833  1.19927192]\n",
      " [-0.52466846  0.30893889  0.71533257 -0.83672571  1.16725731]] [[ 0.47440499  0.7602427   0.27466357 -0.11602929]\n",
      " [-0.66011059 -0.78236425 -0.78290999 -0.14482516]\n",
      " [ 0.00526111 -0.55506396 -0.5412935  -0.44344783]\n",
      " [-0.74196267 -0.17361383  0.46471503  0.23099677]\n",
      " [ 0.1629871  -1.3043946  -0.73954773  0.36895502]]\n",
      "8000 0.658414 [[-0.22453196  1.16676664 -0.9549337   0.49442226  1.88911414]\n",
      " [-0.59249866  0.58806598  0.79236585 -0.80638677  1.79519653]] [[ 0.4820613   0.98596066  0.30360758 -0.10306893]\n",
      " [-0.65610796 -0.86572212 -0.84092563 -0.14112774]\n",
      " [ 0.03438305 -0.48874199 -0.54031342 -0.40754348]\n",
      " [-0.73611873 -0.03730044  0.45277587  0.24397056]\n",
      " [ 0.24401329 -1.85094655 -1.01463068  0.48245606]]\n",
      "9000 0.561136 [[-0.6278131   1.60072815 -1.04975307  0.55140215  3.11958838]\n",
      " [-0.77835119  1.0726949   0.88400507 -0.69978422  2.96477509]] [[ 0.57274687  1.41320097  0.33661431 -0.00517143]\n",
      " [-0.70617783 -1.14785528 -0.90138561 -0.21871383]\n",
      " [ 0.11276853 -0.42463046 -0.54778862 -0.31991199]\n",
      " [-0.70911556  0.19192867  0.45042321  0.26500145]\n",
      " [ 0.41727617 -3.24401832 -1.59540904  0.68882984]]\n",
      "10000 0.491163 [[-1.01360917  1.87383246 -1.22636724  0.82142413  3.99301648]\n",
      " [-1.03812778  1.31380963  0.90014118 -0.44486874  3.8150785 ]] [[ 1.0360297   1.72800434  0.20044324  0.27281389]\n",
      " [-1.03831387 -1.4743588  -0.88223547 -0.52618653]\n",
      " [ 0.34108829 -0.43046558 -0.61410993 -0.1982982 ]\n",
      " [-0.73040116  0.30805722  0.4324035   0.19713299]\n",
      " [ 0.56823432 -4.43015432 -2.07501078  0.69949758]]\n",
      "11000 0.281819 [[ -1.17580616e+00   1.76689219e+00  -1.70330310e+00   1.30805433e+00\n",
      "    4.59337521e+00]\n",
      " [ -1.71775067e+00   1.48703563e+00   8.02258015e-01   6.58140925e-04\n",
      "    4.32073736e+00]] [[ 2.62322354  1.89445782 -0.06764238  0.76721162]\n",
      " [-2.39265084 -1.75113904 -0.50210279 -1.21386206]\n",
      " [ 0.85690695 -0.44323888 -0.66850901 -0.04625603]\n",
      " [-1.06390858  0.23382621  0.61743069 -0.11550949]\n",
      " [ 0.84263945 -5.28272343 -2.26931691  0.5734176 ]]\n",
      "12000 0.0648966 [[-1.58916509  2.0272429  -2.06633306  1.56150484  4.96525717]\n",
      " [-2.43286037  2.21576858  0.87168258  0.16030329  4.60992622]] [[ 4.03987122  2.11847758 -0.43227518  1.18470156]\n",
      " [-3.7547102  -1.90375555  0.50949317 -1.71137893]\n",
      " [ 1.24722767 -0.35898846 -0.70731539  0.08965409]\n",
      " [-1.37982929  0.13236453  1.19740975 -0.25944003]\n",
      " [ 1.03974497 -5.86659193 -2.19327331  0.81671762]]\n",
      "13000 0.0307618 [[-1.78567827  2.17572689 -2.1811552   1.60153532  5.15190363]\n",
      " [-2.63060284  2.48044944  0.94716275  0.15727174  4.75595951]] [[ 4.44402552  2.24763179 -0.64924705  1.29531062]\n",
      " [-4.16285801 -1.97845066  0.94282925 -1.89530134]\n",
      " [ 1.35670769 -0.30612034 -0.74004441  0.12801109]\n",
      " [-1.47169828  0.07165808  1.33723378 -0.29962793]\n",
      " [ 1.09720254 -6.16128826 -2.48126554  1.0363152 ]]\n",
      "14000 0.0191499 [[-1.88974369  2.25842786 -2.24033594  1.61035669  5.27134514]\n",
      " [-2.7299304   2.62377644  0.99470532  0.1480817   4.84951448]] [[ 4.63709402  2.31312728 -0.76891047  1.33778322]\n",
      " [-4.36641741 -2.02122951  1.19461048 -2.00880146]\n",
      " [ 1.4073993  -0.27830678 -0.75247389  0.14436245]\n",
      " [-1.51893675  0.0288969   1.39666474 -0.33236599]\n",
      " [ 1.1192317  -6.33959198 -2.72316504  1.17544377]]\n",
      "15000 0.0135298 [[-1.95717442  2.31510878 -2.27874923  1.61278391  5.35704613]\n",
      " [-2.79275465  2.71921563  1.02841115  0.13950527  4.91763735]] [[  4.75513172e+00   2.35433245e+00  -8.47714603e-01   1.35911798e+00]\n",
      " [ -4.49403381e+00  -2.04920912e+00   1.37464905e+00  -2.08979607e+00]\n",
      " [  1.43810463e+00  -2.60891527e-01  -7.58529365e-01   1.54239297e-01]\n",
      " [ -1.54897738e+00  -1.36113446e-03   1.43616819e+00  -3.58524472e-01]\n",
      " [  1.13093340e+00  -6.46160126e+00  -2.90911698e+00   1.27700055e+00]]\n",
      "16000 0.0102909 [[-2.00583744  2.35817456 -2.30655074  1.61323762  5.42292786]\n",
      " [-2.83745217  2.78968692  1.05423748  0.13168316  4.9708252 ]] [[ 4.83674145  2.38354182 -0.90528691  1.37102377]\n",
      " [-4.58386087 -2.06924796  1.51440382 -2.15209579]\n",
      " [ 1.4592365  -0.24875973 -0.76225644  0.16119589]\n",
      " [-1.5702914  -0.02390224  1.46640313 -0.3800219 ]\n",
      " [ 1.1382854  -6.55213594 -3.05679417  1.35721672]]\n",
      "17000 0.00821473 [[-2.04333639  2.39289618 -2.32801557  1.61295915  5.4759531 ]\n",
      " [-2.87159705  2.8450408   1.07502866  0.12450776  5.01422977]] [[ 4.89752436  2.40576577 -0.9501704   1.37790751]\n",
      " [-4.65169716 -2.08450055  1.62810361 -2.20236254]\n",
      " [ 1.4749186  -0.23971532 -0.76496899  0.16651279]\n",
      " [-1.58646321 -0.04146526  1.49102914 -0.39820096]\n",
      " [ 1.14339745 -6.62305117 -3.17802072  1.42364848]]\n",
      "18000 0.00678455 [[-2.0735302   2.42197895 -2.34531999  1.61240053  5.52003717]\n",
      " [-2.89894795  2.89034295  1.09234381  0.11788552  5.05074835]] [[ 4.94511223  2.42347956 -0.98672676  1.3818301 ]\n",
      " [-4.7054081  -2.09661818  1.72357023 -2.24429131]\n",
      " [ 1.48715556 -0.23265071 -0.76716626  0.17078765]\n",
      " [-1.59930182 -0.05563472  1.51181936 -0.41392913]\n",
      " [ 1.14719808 -6.68075943 -3.28017998  1.48042166]]\n",
      "19000 0.00574677 [[-2.09861851  2.44699192 -2.35971093  1.6117183   5.55758953]\n",
      " [-2.9216063   2.92851877  1.10712302  0.11174159  5.08217287]] [[ 4.98373127  2.4380765  -1.0174464   1.38389432]\n",
      " [-4.74940538 -2.10655642  1.80558956 -2.2801342 ]\n",
      " [ 1.49705279 -0.22694154 -0.7690677   0.17434664]\n",
      " [-1.60983324 -0.06737936  1.5297972  -0.42778113]\n",
      " [ 1.15016794 -6.72906399 -3.36805606  1.53003979]]\n",
      "20000 0.00496355 [[-2.11996174  2.46893144 -2.3719573   1.61100304  5.5901804 ]\n",
      " [-2.94085479  2.96140385  1.11997759  0.10601599  5.10967493]] [[ 5.01591873  2.45040512 -1.04386961  1.38473511]\n",
      " [-4.7863822  -2.11491013  1.87730443 -2.31135488]\n",
      " [ 1.5052768  -0.22220674 -0.77078122  0.17738651]\n",
      " [-1.61868846 -0.07732356  1.54562163 -0.44015351]\n",
      " [ 1.15257192 -6.77037764 -3.44488502  1.57413781]]\n",
      "[array([[ 0.0050997 ],\n",
      "       [ 0.99617636],\n",
      "       [ 0.99435812],\n",
      "       [ 0.0052388 ]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Use 'Deep' neural network to solve XOR problem. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('xor_dataset.txt', unpack=True)\n",
    "\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Deep network configuration.: Use more layers. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,5], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [5,4], -1.0, 1.0))\n",
    "W3 = tf.Variable(tf.random_uniform( [4,1], -1.0, 1.0))\n",
    "\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([5]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([4]), name=\"Bias2\")\n",
    "b3 = tf.Variable(tf.zeros([1]), name=\"Bias3\")\n",
    "\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "L3 =  tf.sigmoid(tf.matmul(L2,W2)+b2)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L3,W3) + b3)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
